{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Home Price - Fine-Tune Base Model \n",
    "\n",
    "### *Introduction*  \n",
    "The goal of this project is to makes predictions about the future sale prices of homes. The prediction results are evaluated on **Mean Absolute Error** between the predicted log error and the actual log error. The logerror (target variable) is defined as ***logerror=log(Zestimate)âˆ’log(SalePrice)*** and is recorded in the training data. \n",
    "\n",
    "In the previous notebooks, the data which contains the list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) data in 2016 were analyzed and cleaned. Base models were built and optimized using the cleaned dataset. \n",
    "\n",
    "### *About This Notebook*\n",
    "This notebook experiments with **model stacking** using the previously optimized models (Ridge, KNeighborsRegressor, RandomForestRegressor, and GradientBoostingRegressor). \n",
    "\n",
    "***In the first level of prediction***   \n",
    "a. The 4 models are used to train *(k-1)* (*k*: number of folds) folds of train set and predict the out-of-fold train set to result in a new train set containing the predictions of the 4 models as new features.     \n",
    "b. Similarly, each model trained on the *(k-1)* folds of train set is used to predict the entire test set, leading to *k* results which are averaged to obtained a mean prediction for each model. The predictions of the 4 models thus result in a new test set with 4 new features.    \n",
    "\n",
    "***In the first level of prediction,***   \n",
    "a. The new train set (with the original train labels) is used train a XGBoost model.   \n",
    "b. The trained model is used to predict the new test set to obtain the final result.   \n",
    " \n",
    "The mean absolute error of prediction on test set is:\n",
    "- 0.06708028229370397\n",
    "\n",
    "***Next Step:***  \n",
    "Try different combinations of base models for stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 | Package and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate random seed\n",
    "SEED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 | Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "\n",
    "def load_data(path, file_name):\n",
    "    \"\"\"load csv data and return dataframe\"\"\"\n",
    "    csv_path = os.path.join(path, file_name)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load train_merge.csv - created in Notebook1\n",
    "train_merge = load_data(DATA_PATH, file_name='train_merge.csv')\n",
    "# drop `transactiondate` and `parcelid` in train\n",
    "train_merge.drop(['transactiondate', 'parcelid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load prop_downsized.csv - created in Notebook1\n",
    "prop = load_data(DATA_PATH, file_name='prop_downsized.csv')\n",
    "# drop `parcelid` in prop\n",
    "prop.drop(['parcelid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (72220, 58)\n",
      "Test set size: (18055, 58)\n"
     ]
    }
   ],
   "source": [
    "# set aside a test set\n",
    "train_set, test_set = train_test_split(train_merge, test_size=0.2, random_state=SEED)\n",
    "print('Training set size: {}\\nTest set size: {}'.format(train_set.shape, test_set.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "train_wo_outlier = train_set[(train_set.logerror > -0.4) & (train_set.logerror < 0.42)]\n",
    "train_w_outlier = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_wo_outlier['logerror'].values\n",
    "X_train = train_wo_outlier.drop(['logerror'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"select desired features and drop the rest\"\"\"\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"add new features including average size of rooms, ratio between living area and lot size,\n",
    "    ratio between property tax and total tax, and ratio between structure value and land value\"\"\"\n",
    "    def __init__(self, add_new_feature=True):\n",
    "        self.add_new_feature = add_new_feature\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # define new features\n",
    "        N_AvgSize = X['calculatedfinishedsquarefeet']/(X['bedroomcnt'] + X['bathroomcnt'] + 1)\n",
    "        N_PropLot = X['calculatedfinishedsquarefeet']/X['lotsizesquarefeet']\n",
    "        N_ValueRatio = X['taxamount']/X['taxvaluedollarcnt']\n",
    "        N_StructLand = X['structuretaxvaluedollarcnt']/X['landtaxvaluedollarcnt']\n",
    "        # add new features if True\n",
    "        if self.add_new_feature:\n",
    "            return np.c_[X, N_AvgSize, N_PropLot, N_ValueRatio, N_StructLand]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"drop features with percentage of missing missing values larger than missing_pct\"\"\"\n",
    "    def __init__(self, missing_pct=1, drop_cols=[]):\n",
    "        self.missing_pct = missing_pct # missing value percentage threshold\n",
    "        self.drop_cols = drop_cols # initialize columns to drop\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            if pd.isnull(X[col]).sum()/X.shape[0] >= self.missing_pct:\n",
    "                self.drop_cols.append(col)\n",
    "        X = X.drop(self.drop_cols, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CatTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"categorival feature transformer: impute categorical value and encode categories\"\"\"\n",
    "    def __init__(self, cat_dict):\n",
    "        self.cat_dict = cat_dict\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            if X[col].dtype == 'O':\n",
    "                X[col].fillna('-99', inplace=True)\n",
    "            X[col].fillna(-99, inplace=True)\n",
    "            X[col] = X[col].astype('category', categories=self.cat_dict[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DummyEncoder(TransformerMixin):\n",
    "    \"\"\"create dummy variables\"\"\"\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return pd.get_dummies(X, columns=self.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numerical features\n",
    "num_features = ['basementsqft', 'bathroomcnt', 'bedroomcnt', 'calculatedbathnbr', \\\n",
    "             'threequarterbathnbr', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet',\\\n",
    "             'finishedsquarefeet6', 'finishedsquarefeet12', 'finishedsquarefeet13', \\\n",
    "             'finishedsquarefeet15', 'finishedsquarefeet50', 'fireplacecnt', 'fullbathcnt', \\\n",
    "             'garagecarcnt', 'garagetotalsqft', 'latitude', 'longitude', 'lotsizesquarefeet', \\\n",
    "             'numberofstories', 'poolcnt', 'poolsizesum', 'roomcnt', \\\n",
    "             'unitcnt', 'yardbuildingsqft17', 'yardbuildingsqft26', 'yearbuilt', \\\n",
    "             'taxvaluedollarcnt', 'structuretaxvaluedollarcnt', 'landtaxvaluedollarcnt', \\\n",
    "             'taxamount', 'assessmentyear']\n",
    "\n",
    "# categorical features\n",
    "cat_features = ['airconditioningtypeid', 'decktypeid', 'architecturalstyletypeid', \\\n",
    "               'buildingclasstypeid', 'heatingorsystemtypeid', 'fips', 'fireplaceflag', \\\n",
    "               'hashottuborspa', 'pooltypeid10', 'pooltypeid2', 'propertylandusetypeid', \\\n",
    "               'propertyzoningdesc', 'regionidcounty', 'taxdelinquencyflag', 'propertycountylandusecode', \\\n",
    "                'rawcensustractandblock', 'censustractandblock', 'regionidcity', 'regionidzip', \\\n",
    "                'regionidneighborhood', 'storytypeid', 'pooltypeid7', 'typeconstructiontypeid', 'taxdelinquencyyear']\n",
    "\n",
    "# potential features to drop (categorical variables with large number of levels) \n",
    "drop_features = ['propertycountylandusecode', 'rawcensustractandblock', 'censustractandblock', \\\n",
    "                 'regionidcity', 'regionidzip', 'regionidneighborhood', 'propertyzoningdesc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/categories.pickle', 'rb') as handle:\n",
    "    categories = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline for numerical features\n",
    "num_pipe = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_features)),\n",
    "        ('feature_dropper', FeatureDropper(missing_pct=0.95)),\n",
    "        ('feature_adder', FeatureAdder(add_new_feature=True)),\n",
    "        ('imputer', Imputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline for categorical features\n",
    "cat_pipe = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_features)), \n",
    "        ('feature_dropper', FeatureDropper(missing_pct=0.95, drop_cols=drop_features)),\n",
    "        ('cat_transform', CatTransformer(categories)),\n",
    "        ('get_dummy', DummyEncoder())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# full pipeline combining pipelines for numerical and categorical features\n",
    "full_pipe = FeatureUnion([\n",
    "        ('num_pipeline', num_pipe),\n",
    "        ('cat_pipeline', cat_pipe)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform features with full_pipe\n",
    "X_train_transformed = full_pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test features and labels\n",
    "y_test = test_set['logerror'].values\n",
    "X_test = test_set.drop(['logerror'], axis=1)\n",
    "X_test_transformed = full_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 | Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 First level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiate parameters\n",
    "ntrain = X_train_transformed.shape[0]\n",
    "ntest = X_test_transformed.shape[0]\n",
    "NFOLDS = 5\n",
    "kfold = KFold(n_splits= NFOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SklearnHelper(object):\n",
    "    \"\"\"extend the Sklearn method (fit, predict) to all classifiers\"\"\"\n",
    "    def __init__(self, model, params=None):\n",
    "        self.model = model(**params)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(model, X_train, y_train, X_test):\n",
    "    \"\"\"get out-of-fold prediction\"\"\"\n",
    "    \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    # fit model with NFOLDS-1 folds and test on left-out fold as well sa test set\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(X_train)):\n",
    "        X_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        X_te = X_train[test_index]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = model.predict(X_te)\n",
    "        oof_test_skf[i, :] = model.predict(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters for the base models\n",
    "ridge_params = {\n",
    "    'alpha': 4000,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "knn_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_neighbors': 80,\n",
    "    'p': 1\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500, \n",
    "    'max_depth': 5,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': 80, \n",
    "    'max_depth': 3,\n",
    "    'random_state': SEED\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create objects of the models\n",
    "ridge = SklearnHelper(model=Ridge, params=ridge_params)\n",
    "knn = SklearnHelper(model=KNeighborsRegressor, params=knn_params)\n",
    "rf = SklearnHelper(model=RandomForestRegressor, params=rf_params)\n",
    "gb = SklearnHelper(model=GradientBoostingRegressor, params=gb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OOF train and test predictions\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, X_train_transformed, \n",
    "                                          y_train, X_test_transformed)\n",
    "knn_oof_train, knn_oof_test = get_oof(knn, X_train_transformed, \n",
    "                                      y_train, X_test_transformed)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf, X_train_transformed, \n",
    "                                    y_train, X_test_transformed) \n",
    "gb_oof_train, gb_oof_test = get_oof(gb, X_train_transformed, \n",
    "                                    y_train, X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gb</th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004632</td>\n",
       "      <td>-0.006104</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.005834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007503</td>\n",
       "      <td>-0.007574</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>-0.003053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.009916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014528</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.015111</td>\n",
       "      <td>-0.016555</td>\n",
       "      <td>-0.022401</td>\n",
       "      <td>-0.001636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gb       knn        rf     ridge\n",
       "0  0.004632 -0.006104  0.004802  0.005834\n",
       "1 -0.007503 -0.007574  0.004621 -0.003053\n",
       "2  0.010662  0.006564  0.008791  0.009916\n",
       "3  0.014528 -0.003636  0.008900  0.003424\n",
       "4 -0.015111 -0.016555 -0.022401 -0.001636"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd level prediction with the first level output\n",
    "base_pred_train = pd.DataFrame({\n",
    "        'ridge': ridge_oof_train.ravel(),\n",
    "        'knn': knn_oof_train.ravel(),\n",
    "        'rf': rf_oof_train.ravel(),\n",
    "        'gb': gb_oof_train.ravel()\n",
    "    })\n",
    "base_pred_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_pred_test = pd.DataFrame({\n",
    "        'ridge': ridge_oof_test.ravel(),\n",
    "        'knn': knn_oof_test.ravel(),\n",
    "        'rf': rf_oof_test.ravel(),\n",
    "        'gb': gb_oof_test.ravel()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGyCAYAAADau9wtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqRL/H7oS4OTzupj6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be778d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation of first level output\n",
    "corr = base_pred_train.corr()\n",
    "\n",
    "# plot correlation matrix\n",
    "f, ax = plt.subplots(figsize=(6, 5))\n",
    "mask = np.zeros_like(corr, dtype=np.bool) # Generate a mask for the upper triangle\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation matrix of first level output');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gb</th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "      <th>ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.871209</td>\n",
       "      <td>0.534937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.455252</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377244</td>\n",
       "      <td>0.422510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.871209</td>\n",
       "      <td>0.377244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.534937</td>\n",
       "      <td>0.422510</td>\n",
       "      <td>0.484763</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gb       knn        rf     ridge\n",
       "gb     1.000000  0.455252  0.871209  0.534937\n",
       "knn    0.455252  1.000000  0.377244  0.422510\n",
       "rf     0.871209  0.377244  1.000000  0.484763\n",
       "ridge  0.534937  0.422510  0.484763  1.000000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 models show some correlation with each other, especially between RandomForest and GradientBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save base_pred_train and base_pred_test\n",
    "base_pred_train.to_csv('../data/base_pred_train.csv', index=False)\n",
    "base_pred_test.to_csv('../data/base_pred_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Second Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions from first level output as the new train and test set\n",
    "X_train_2 = np.concatenate((ridge_oof_train, knn_oof_train, rf_oof_train, gb_oof_train), axis=1)\n",
    "X_test_2 = np.concatenate((ridge_oof_test, knn_oof_test, rf_oof_test, gb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fit(alg, X_train, y_train, useTrainCV=True, cv_folds=NFOLDS, early_stopping_rounds=50):\n",
    "    \"\"\"function to create XGBoost models and perform cross-validation\"\"\"\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        dtrain = xgb.DMatrix(X_train, y_train)\n",
    "        cvresult = xgb.cv(xgb_param, \n",
    "                          dtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], \n",
    "                          nfold=cv_folds,\n",
    "                          metrics='mae', \n",
    "                          early_stopping_rounds=early_stopping_rounds,\n",
    "                          show_stdv=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    # Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train, eval_metric='mae')\n",
    "        \n",
    "    # Predict training set:\n",
    "    pred = alg.predict(X_train)\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Best Iteration: %i\" % cvresult.shape[0])\n",
    "    print(\"MAE : %.4g\" % mean_absolute_error(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Best Iteration: 48\n",
      "MAE : 0.05267\n"
     ]
    }
   ],
   "source": [
    "# tune the learning rate & number of trees\n",
    "xgb1 = XGBRegressor(learning_rate =0.03,\n",
    "                    n_estimators=500,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    objective='reg:linear',\n",
    "                    base_score=0.0107,\n",
    "                    seed=SEED)\n",
    "model_fit(xgb1, X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 1}\n",
      "-0.05289824403\n"
     ]
    }
   ],
   "source": [
    "# tune max_depth & min_chile_weight\n",
    "param_test1 = {'max_depth': range(3,10,2), 'min_child_weight': range(1,6,2)}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=5, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.8, colsample_bytree=0.8, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_1 = GridSearchCV(model, param_grid=param_test1, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_1.fit(X_train_2, y_train)\n",
    "print(grid_1.best_params_) \n",
    "print(grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "-0.05289824403\n"
     ]
    }
   ],
   "source": [
    "# tune gamma\n",
    "param_test2 = {'gamma': [i/10.0 for i in range(0,5)]}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=3, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.8, colsample_bytree=0.8, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_2 = GridSearchCV(model, param_grid=param_test2, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_2.fit(X_train_2, y_train)\n",
    "\n",
    "print(grid_2.best_params_) \n",
    "print(grid_2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Best Iteration: 48\n",
      "MAE : 0.05283\n"
     ]
    }
   ],
   "source": [
    "# re-calibrate the number of boosting rounds for the updated parameters\n",
    "xgb2 = XGBRegressor(learning_rate =0.03,\n",
    "                    n_estimators=48,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    objective='reg:linear',\n",
    "                    base_score=0.0107,\n",
    "                    seed=SEED)\n",
    "model_fit(xgb2, X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.7, 'colsample_bytree': 0.6}\n",
      "-0.0528871828661\n"
     ]
    }
   ],
   "source": [
    "# tune subsample & colsample_bytree\n",
    "param_test3 = {'subsample':[i/10.0 for i in range(6,10)],\n",
    "               'colsample_bytree':[i/10.0 for i in range(6,10)]}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=3, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.8, colsample_bytree=0.8, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_3 = GridSearchCV(model, param_grid=param_test3, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_3.fit(X_train_2, y_train)\n",
    "\n",
    "print(grid_3.best_params_) \n",
    "print(grid_3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.7, 'colsample_bytree': 0.55}\n",
      "-0.0528871828661\n"
     ]
    }
   ],
   "source": [
    "# fine tune subsample & colsample_bytree\n",
    "param_test4 = {'subsample':[i/100.0 for i in range(65, 80, 5)],\n",
    "               'colsample_bytree':[i/100.0 for i in range(55, 70, 5)]}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=3, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.8, colsample_bytree=0.8, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_4 = GridSearchCV(model, param_grid=param_test4, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_4.fit(X_train_2, y_train)\n",
    "\n",
    "print(grid_4.best_params_) \n",
    "print(grid_4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.1}\n",
      "-0.0528852704727\n"
     ]
    }
   ],
   "source": [
    "# tune regularization parameters\n",
    "param_test5 = {'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=3, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.7, colsample_bytree=0.55, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_5 = GridSearchCV(model, param_grid=param_test5, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_5.fit(X_train_2, y_train)\n",
    "\n",
    "print(grid_5.best_params_) \n",
    "print(grid_5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.1}\n",
      "-0.0528852704727\n"
     ]
    }
   ],
   "source": [
    "# fine tune regularization parameters\n",
    "param_test6 = {'reg_alpha': [0.05, 0.1, 0.15]}\n",
    "model = XGBRegressor(learning_rate=0.03, n_estimators=48, max_depth=3, min_child_weight=1, \\\n",
    "                     gamma=0, subsample=0.7, colsample_bytree=0.55, objective='reg:linear', \\\n",
    "                     base_score=0.0107, seed=SEED)\n",
    "grid_6 = GridSearchCV(model, param_grid=param_test6, scoring='neg_mean_absolute_error', \\\n",
    "                      n_jobs=2, cv=5)\n",
    "grid_6.fit(X_train_2, y_train)\n",
    "\n",
    "print(grid_6.best_params_) \n",
    "print(grid_6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Best Iteration: 58\n",
      "MAE : 0.05281\n"
     ]
    }
   ],
   "source": [
    "# check the impact of the tunning\n",
    "xgb3 = XGBRegressor(learning_rate =0.03,\n",
    "                    n_estimators=500,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.7,\n",
    "                    colsample_bytree=0.55,\n",
    "                    reg_alpha=0.1,\n",
    "                    objective='reg:linear',\n",
    "                    base_score=0.0107,\n",
    "                    seed=SEED)\n",
    "model_fit(xgb3, X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Best Iteration: 186\n",
      "MAE : 0.05281\n"
     ]
    }
   ],
   "source": [
    "# lower the learning rate and add more trees\n",
    "xgb4 = XGBRegressor(learning_rate =0.01,\n",
    "                    n_estimators=500,\n",
    "                    max_depth=3,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.7,\n",
    "                    colsample_bytree=0.55,\n",
    "                    reg_alpha=0.1,\n",
    "                    objective='reg:linear',\n",
    "                    base_score=0.0107,\n",
    "                    seed=SEED)\n",
    "model_fit(xgb4, X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (test): 0.06708028229370397\n"
     ]
    }
   ],
   "source": [
    "best_model = XGBRegressor(learning_rate=0.01, n_estimators=186, max_depth=3, \\\n",
    "                          min_child_weight=1, gamma=0, subsample=0.7, colsample_bytree=0.55, \\\n",
    "                          objective='reg:linear', reg_alpha=0.1, base_score=0.0107, seed=SEED)\n",
    "best_model.fit(X_train_2, y_train)\n",
    "pred = best_model.predict(X_test_2)\n",
    "print('Mean Absolute Error (test): {}'.format(mean_absolute_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE END** "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
